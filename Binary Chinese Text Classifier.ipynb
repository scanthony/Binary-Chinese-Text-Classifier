{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import metrics\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras import callbacks\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import collections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv('./call_no3_csv.csv',encoding='utf-8',header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     features CLASS_NO1\n",
      "0       海洋与海岸  LIGONGKE\n",
      "1   头痛151个怎么办  LIGONGKE\n",
      "2       丘陵与平原  LIGONGKE\n",
      "3  颈椎病132个怎么办  LIGONGKE\n",
      "4       山地与高原  LIGONGKE\n"
     ]
    }
   ],
   "source": [
    "print(df_raw[:5])\n",
    "sample_n = len(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop noisy characters\n",
    "def drop_noise(x):\n",
    "    noise = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '1', '2', '3', '4', '5', '6', '7', '8', '9', '0', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '，', '：', '。', '“', '”', '１','２','３','４','５','６','７','８','９','０', ':', ' ', '的']\n",
    "    result = x.copy()\n",
    "    for i, ii in enumerate(x):\n",
    "        for j, jj in enumerate(noise):\n",
    "            if jj == ii:\n",
    "                result.remove(ii)\n",
    "                \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listizer = lambda x: list(x)\n",
    "setizer = lambda x: set(x)\n",
    "\n",
    "df_drop_noise=df_raw.copy()\n",
    "\n",
    "df_drop_noise['features'] = df_drop_noise['features'].apply(listizer)\n",
    "df_drop_noise['features'] = df_drop_noise['features'].apply(drop_noise)\n",
    "\n",
    "df_str=df_drop_noise.copy()\n",
    "#df_set=df_drop_noise.copy()\n",
    "df_list=df_drop_noise.copy()\n",
    "\n",
    "df_str['features'] = df_str['features'].apply(listizer)\n",
    "\n",
    "#df_set['features'] = df_set['features'].apply(setizer)\n",
    "df_list['features'] = df_list['features'].apply(listizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>CLASS_NO1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[海, 洋, 与, 海, 岸]</td>\n",
       "      <td>LIGONGKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[头, 痛, 个, 怎, 么, 办]</td>\n",
       "      <td>LIGONGKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[丘, 陵, 与, 平, 原]</td>\n",
       "      <td>LIGONGKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[颈, 椎, 病, 个, 怎, 么, 办]</td>\n",
       "      <td>LIGONGKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[山, 地, 与, 高, 原]</td>\n",
       "      <td>LIGONGKE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                features CLASS_NO1\n",
       "0        [海, 洋, 与, 海, 岸]  LIGONGKE\n",
       "1     [头, 痛, 个, 怎, 么, 办]  LIGONGKE\n",
       "2        [丘, 陵, 与, 平, 原]  LIGONGKE\n",
       "3  [颈, 椎, 病, 个, 怎, 么, 办]  LIGONGKE\n",
       "4        [山, 地, 与, 高, 原]  LIGONGKE"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4487\n"
     ]
    }
   ],
   "source": [
    "# Create Corpus\n",
    "vocab = []\n",
    "for words in df_str['features']:\n",
    "    for word in words:\n",
    "        vocab.append(word)\n",
    "vocab_list = vocab\n",
    "vocab = set(vocab)\n",
    "#print(vocab)\n",
    "freq_dict = collections.Counter(vocab_list)\n",
    "\n",
    "# Create dict\n",
    "word2index = {}\n",
    "ii = 1\n",
    "for i,word in enumerate(vocab):\n",
    "    word2index[word] = ii\n",
    "    ii += 1\n",
    "\n",
    "print(len(word2index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('国', 12641), ('中', 10596), ('文', 8114), ('学', 7149), ('与', 6941), ('研', 5438), ('究', 5271), ('人', 4390), ('大', 4217), ('集', 4166), ('史', 4129), ('代', 4037), ('民', 3741), ('年', 3433), ('生', 3310), ('法', 3060), ('理', 2989), ('化', 2968), ('论', 2851), ('一', 2848), ('全', 2797), ('编', 2783), ('书', 2697), ('家', 2682), ('事', 2633), ('新', 2616), ('小', 2406), ('经', 2377), ('本', 2364), ('世', 2352), ('物', 2174), ('古', 2155), ('会', 2096), ('地', 2088), ('之', 1976), ('发', 1967), ('教', 1925), ('传', 1911), ('战', 1892), ('业', 1854), ('我', 1837), ('子', 1827), ('和', 1823), ('术', 1815), ('图', 1790), ('四', 1782), ('美', 1768), ('界', 1738), ('记', 1725), ('实', 1703)]\n",
      "4487\n"
     ]
    }
   ],
   "source": [
    "# Frequency\n",
    "\n",
    "freq_dict = collections.Counter(vocab_list)\n",
    "print(freq_dict.most_common(50))\n",
    "\n",
    "print(len(word2index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Least Common Func\n",
    "from operator import itemgetter\n",
    "import heapq\n",
    "import collections\n",
    "def least_common_values(array, to_find=None):\n",
    "    counter = collections.Counter(array)\n",
    "    if to_find is None:\n",
    "        return sorted(counter.items(), key=itemgetter(1), reverse=False)\n",
    "    return heapq.nsmallest(to_find, counter.items(), key=itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('疡', 1),\n",
       " ('堵', 1),\n",
       " ('佯', 1),\n",
       " ('槛', 1),\n",
       " ('茆', 1),\n",
       " ('給', 1),\n",
       " ('蜷', 1),\n",
       " ('─', 1),\n",
       " ('勐', 1)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "least_common_values(freq_dict, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index2word = {ii: word for word, ii in word2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2149"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2index[\"波\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Convert using bag of words\n",
    "vocab_size = len(word2index)\n",
    "#features = pd.DataFrame(np.random.uniform(0,1,size=(sample_n, 100)))\n",
    "#features = np.zeros(shape=(sample_n, vocab_size))\n",
    "max_len = 80\n",
    "features = np.zeros(shape=(sample_n, max_len), dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "(66431, 80)\n",
      "30.106426216675953\n",
      "(66431, 80)\n",
      "60.212852433351905\n",
      "(66431, 80)\n",
      "90.31927865002784\n",
      "(66431, 80)\n"
     ]
    }
   ],
   "source": [
    "for ii, row in enumerate(df_list['features']):\n",
    "    #print(row)\n",
    "    for jj, word in enumerate(row):\n",
    "        if len(row) <= 80:\n",
    "            len_row = 80\n",
    "        else:\n",
    "            len_row = len(row)\n",
    "        \n",
    "        try:\n",
    "            features[ii][len_row - jj] = word2index[word]\n",
    "        except:\n",
    "            pass\n",
    "    if ii % 20000 == 0:\n",
    "        print(ii/sample_n*100)\n",
    "        print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0, 1696, 1361,\n",
       "       1054, 1003, 4247])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ONE HOT ENCODE LABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_label=df_list.copy()\n",
    "def upperiser(x):\n",
    "    if str(x) != 'nan':\n",
    "        return str(x).upper()\n",
    "    else:\n",
    "        return 'WENKE'\n",
    "\n",
    "df_label['CLASS_NO1'] = df_label['CLASS_NO1'].apply(upperiser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLASS_NO1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LIGONGKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LIGONGKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LIGONGKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LIGONGKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LIGONGKE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CLASS_NO1\n",
       "0  LIGONGKE\n",
       "1  LIGONGKE\n",
       "2  LIGONGKE\n",
       "3  LIGONGKE\n",
       "4  LIGONGKE"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label=df_label.drop('features', axis=1)\n",
    "df_label[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LIGONGKE', 'WENKE'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_label = np.array(df_label['CLASS_NO1'])\n",
    "\n",
    "set_label = set(np_label)\n",
    "set_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num2class = {'1': 'WENKE',\n",
    "'2': 'LIGONGKE'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LIGONGKE': '2', 'WENKE': '1'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class2num = {ii: word for word, ii in num2class.items()}\n",
    "class2num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def class2ohfunc(classno):\n",
    "    oh = [0,0]\n",
    "    oh[int(class2num[classno])-1] = 1\n",
    "    return np.array(oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLASS_NO1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CLASS_NO1\n",
       "0    [0, 1]\n",
       "1    [0, 1]\n",
       "2    [0, 1]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label['CLASS_NO1'] = df_label['CLASS_NO1'].apply(class2ohfunc)\n",
    "df_label[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4487\n",
      "(0, 2)\n"
     ]
    }
   ],
   "source": [
    "features.shape\n",
    "print(vocab_size)\n",
    "print(df_list[-2421:3205].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = np.array(df_label['CLASS_NO1'])\n",
    "labels = np.array(labels.tolist())\n",
    "trainX = features[:-6124]\n",
    "trainY = labels[:-6124]\n",
    "testX = features[-6124:]\n",
    "testY = labels[-6124:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0]\n",
      " [1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(testY[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#trainX = trainX.astype('float32')\n",
    "#trainY = trainY.astype('float32')\n",
    "trainY = np.reshape(trainY, newshape=(len(trainX),2))\n",
    "#testX = testX.astype('float32')\n",
    "#testY = testY.astype('float32')\n",
    "testY = np.reshape(testY, newshape=(len(testX),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60307, 80), (60307, 2))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape, trainY.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-9123d5038a5c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datasets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-b4ccf2ded61b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0miris\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_iris\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miris\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# we only take the first two features.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miris\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'datasets' is not defined"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # we only take the first two features.\n",
    "Y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-239bd099700b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Y' is not defined"
     ]
    }
   ],
   "source": [
    "Y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainYs = np.zeros((len(trainX)))\n",
    "for i, ii in enumerate(trainY):\n",
    "    trainYs[i] = ii[0]\n",
    "\n",
    "testYs = np.zeros((len(testX)))\n",
    "for i, ii in enumerate(testY):\n",
    "    testYs[i] = ii[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainYs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'linear_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-f2e0f6d928af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlogreg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainYs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'linear_model' is not defined"
     ]
    }
   ],
   "source": [
    "logreg = linear_model.LogisticRegression()\n",
    "logreg.fit(trainX, trainYs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logreg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-a76ed3c91495>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlogreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainYs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'logreg' is not defined"
     ]
    }
   ],
   "source": [
    "logreg.score(trainX, trainYs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92553886348791636"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(testX, testYs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAINING SOON STARTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vocab_size = len(word2index)\n",
    "print(features.shape)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the Nerual Network with TFLearn's sample code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(vocab_size, 800, input_length=80))\n",
    "\n",
    "model.add(LSTM(1200))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(600, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(80, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "adam_op = Adam(lr=0.001)\n",
    "#adam_op = Adam()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam_op, metrics=[metrics.categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "60307/60307 [==============================] - 615s - loss: 0.2839 - categorical_accuracy: 0.8959   \n",
      "Epoch 2/6\n",
      "60307/60307 [==============================] - 615s - loss: 0.1992 - categorical_accuracy: 0.9264   \n",
      "Epoch 3/6\n",
      "60307/60307 [==============================] - 613s - loss: 0.1715 - categorical_accuracy: 0.9362   \n",
      "Epoch 4/6\n",
      "60307/60307 [==============================] - 612s - loss: 0.1519 - categorical_accuracy: 0.9438   \n",
      "Epoch 5/6\n",
      "60307/60307 [==============================] - 611s - loss: 0.1372 - categorical_accuracy: 0.9489   \n",
      "Epoch 6/6\n",
      "60307/60307 [==============================] - 613s - loss: 0.1228 - categorical_accuracy: 0.9540   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c7ca0098d0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, trainY, batch_size=32, epochs=6, verbose=1, callbacks=[cbk.TensorBoard(log_dir='./Graph', histogram_freq=22, write_graph=True, write_grads=True, write_images=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.TensorBoard at 0x1c7cb275518>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=32, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)\n",
    "from keras import callbacks\n",
    "callbacks.TensorBoard(log_dir='./keraslogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60307/60307 [==============================] - 158s   \n",
      "\n",
      "0.962806970998\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(trainX, trainY)\n",
    "print(\"\")\n",
    "print(score[1])\n",
    "\n",
    "# 5 epochs: 0.98365032251645745"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6124/6124 [==============================] - 16s    \n",
      "\n",
      "0.928314826911\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(testX, testY)\n",
    "print(\"\")\n",
    "print(score[1])\n",
    "\n",
    "# 5 epochs: 0.9301110387315632\n",
    "# another: 0.933050293926"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  0.]\n"
     ]
    }
   ],
   "source": [
    "try01 = testX[97]\n",
    "result = model.predict(testX)\n",
    "print(result[97])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  0.]\n"
     ]
    }
   ],
   "source": [
    "# Prediction starts here\n",
    "\n",
    "#pred_list = np.zeros(shape=(len(testX),1))\n",
    "#for i, test_feature in enumerate(testX):\n",
    "#    result = model.predict([test_feature])\n",
    " #   pred_list[i][0] = result[0][0]\n",
    "    \n",
    "pred_list = np.zeros(shape=(len(testX),2))\n",
    "results = model.predict(testX)\n",
    "for i, res in enumerate(results):\n",
    "    result = res\n",
    "    if i == 1:\n",
    "        print(res)\n",
    "    for jj in range(2):\n",
    "        pred_list[i][jj] = result[jj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  7.18884349e-01,   2.81115621e-01],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  7.18884349e-01,   2.81115621e-01],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  7.18884349e-01,   2.81115621e-01],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  5.89076042e-01,   4.10923928e-01],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  7.18884349e-01,   2.81115621e-01],\n",
       "       [  7.18884349e-01,   2.81115621e-01],\n",
       "       [  5.84372901e-06,   9.99994159e-01],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  7.18884349e-01,   2.81115621e-01],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   8.85836834e-29],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_list[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def toClassNo(npArray):\n",
    "    i = 0\n",
    "    val = npArray[0]\n",
    "    for jj in range(len(npArray)-1):\n",
    "        if npArray[jj+1] > val:\n",
    "            val = npArray[jj+1]\n",
    "            i = jj + 1\n",
    "    return num2class[str(i+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WENKE', 'WENKE', 'WENKE', 'WENKE', 'WENKE']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6124"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_result_list = [None] * len(testX)\n",
    "for i, result in enumerate(pred_list):\n",
    "    pred_result_list[i] = toClassNo(result)\n",
    "\n",
    "print(pred_result_list[:5])\n",
    "len(pred_result_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>CLASS_NO1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60307</th>\n",
       "      <td>柏杨全集</td>\n",
       "      <td>WENKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60308</th>\n",
       "      <td>四部叢刊 :四編</td>\n",
       "      <td>WENKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60309</th>\n",
       "      <td>四部叢刊 :四編</td>\n",
       "      <td>WENKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60310</th>\n",
       "      <td>四部叢刊 :四編</td>\n",
       "      <td>WENKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60311</th>\n",
       "      <td>四部叢刊 :四編</td>\n",
       "      <td>WENKE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       features CLASS_NO1\n",
       "60307      柏杨全集     WENKE\n",
       "60308  四部叢刊 :四編     WENKE\n",
       "60309  四部叢刊 :四編     WENKE\n",
       "60310  四部叢刊 :四編     WENKE\n",
       "60311  四部叢刊 :四編     WENKE"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw[-6124:-6124+5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame(pred_result_list)\n",
    "tempdf = df_raw.copy()\n",
    "tempdf = tempdf.drop(tempdf.index[:-6124])\n",
    "tempdfa = tempdf['features']\n",
    "tempdfb = tempdf['CLASS_NO1']\n",
    "output = pd.concat([tempdfa, tempdfb], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_pred.to_csv('output1.csv')\n",
    "output.to_csv('output2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
