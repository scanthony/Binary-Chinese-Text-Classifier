{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Binary Book Title Classifier\n",
    "## Based on LSTM Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import metrics\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras import callbacks as cbk\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the dataset into a pandas dataframe\n",
    "df_raw = pd.read_csv('./dataset_full.csv',encoding='utf-8',header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     features CLASS_NO1\n",
      "0       海洋与海岸  sci_tech\n",
      "1   头痛151个怎么办  sci_tech\n",
      "2       丘陵与平原  sci_tech\n",
      "3  颈椎病132个怎么办  sci_tech\n",
      "4       山地与高原  sci_tech\n"
     ]
    }
   ],
   "source": [
    "# Preview the data\n",
    "print(df_raw[:5])\n",
    "sample_n = len(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to drop Arabic numbers, English letters and punctuations\n",
    "def drop_noise(x):\n",
    "    noise = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '1', '2', '3', '4', '5', '6', '7', '8', '9', '0', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '，', '：', '。', '“', '”', '１','２','３','４','５','６','７','８','９','０', ':', ' ', '的']\n",
    "    result = x.copy()\n",
    "    for i, ii in enumerate(x):\n",
    "        for j, jj in enumerate(noise):\n",
    "            if jj == ii:\n",
    "                result.remove(ii)\n",
    "                \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop noises and convert string into a list\n",
    "listizer = lambda x: list(x)\n",
    "setizer = lambda x: set(x)\n",
    "\n",
    "df_list=df_raw.copy()\n",
    "df_list['features'] = df_list['features'].apply(listizer)\n",
    "df_list['features'] = df_list['features'].apply(drop_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>CLASS_NO1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[海, 洋, 与, 海, 岸]</td>\n",
       "      <td>sci_tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[头, 痛, 个, 怎, 么, 办]</td>\n",
       "      <td>sci_tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[丘, 陵, 与, 平, 原]</td>\n",
       "      <td>sci_tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[颈, 椎, 病, 个, 怎, 么, 办]</td>\n",
       "      <td>sci_tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[山, 地, 与, 高, 原]</td>\n",
       "      <td>sci_tech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                features CLASS_NO1\n",
       "0        [海, 洋, 与, 海, 岸]  sci_tech\n",
       "1     [头, 痛, 个, 怎, 么, 办]  sci_tech\n",
       "2        [丘, 陵, 与, 平, 原]  sci_tech\n",
       "3  [颈, 椎, 病, 个, 怎, 么, 办]  sci_tech\n",
       "4        [山, 地, 与, 高, 原]  sci_tech"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the result\n",
    "df_list[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This Cell create the word to index dictionary\n",
    "\n",
    "vocab = []\n",
    "for words in df_list['features']:\n",
    "    for word in words:\n",
    "        vocab.append(word)\n",
    "vocab_list = vocab\n",
    "vocab = set(vocab)\n",
    "#print(vocab)\n",
    "freq_dict = collections.Counter(vocab_list)\n",
    "\n",
    "# Create dict\n",
    "word2index = {}\n",
    "stopwords = []\n",
    "ii = 1\n",
    "for i,word in enumerate(vocab):\n",
    "    if freq_dict[word] >= 10:\n",
    "        # This if-else statement drop the least frequent words from the word2index dictionary\n",
    "        word2index[word] = ii\n",
    "        ii += 1\n",
    "    else: \n",
    "        stopwords.append(word)\n",
    "\n",
    "#print(len(word2index))\n",
    "#print(stopwords[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function will drop the least frequent words from the dataset\n",
    "\n",
    "def drop_stop_words(x):\n",
    "    result = x.copy()\n",
    "    for i, ii in enumerate(x):\n",
    "        for j, jj in enumerate(stopwords):\n",
    "            if jj == ii:\n",
    "                result.remove(ii)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# Use the \"drop_stop_words()\" function to drop least frequent words\n",
    "\n",
    "df_list['features'][:10000] = df_list['features'][:10000].apply(drop_stop_words)\n",
    "print(1)\n",
    "df_list['features'][10000:20000] = df_list['features'][10000:20000].apply(drop_stop_words)\n",
    "print(2)\n",
    "df_list['features'][20000:30000] = df_list['features'][20000:30000].apply(drop_stop_words)\n",
    "print(3)\n",
    "df_list['features'][30000:40000] = df_list['features'][30000:40000].apply(drop_stop_words)\n",
    "print(4)\n",
    "df_list['features'][40000:50000] = df_list['features'][40000:50000].apply(drop_stop_words)\n",
    "print(5)\n",
    "df_list['features'][50000:60000] = df_list['features'][50000:60000].apply(drop_stop_words)\n",
    "print(6)\n",
    "df_list['features'][60000:] = df_list['features'][60000:].apply(drop_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Re-create the vocabulary list, which does not contain the least frequent words\n",
    "vocab = []\n",
    "for words in df_list['features']:\n",
    "    for word in words:\n",
    "        vocab.append(word)\n",
    "vocab_list = vocab\n",
    "vocab = set(vocab)\n",
    "freq_dict = collections.Counter(vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>CLASS_NO1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[海, 洋, 与, 海, 岸]</td>\n",
       "      <td>sci_tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[头, 痛, 个, 怎, 么, 办]</td>\n",
       "      <td>sci_tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[丘, 陵, 与, 平, 原]</td>\n",
       "      <td>sci_tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[颈, 病, 个, 怎, 么, 办]</td>\n",
       "      <td>sci_tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[山, 地, 与, 高, 原]</td>\n",
       "      <td>sci_tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[贫, 血, 个, 怎, 么, 办]</td>\n",
       "      <td>sci_tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[地, 球, 变, 动]</td>\n",
       "      <td>sci_tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[地, 心, 游, 记]</td>\n",
       "      <td>lib_arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[柳, 林, 风, 声]</td>\n",
       "      <td>lib_arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[极, 地, 与, 沙, 漠]</td>\n",
       "      <td>sci_tech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             features CLASS_NO1\n",
       "0     [海, 洋, 与, 海, 岸]  sci_tech\n",
       "1  [头, 痛, 个, 怎, 么, 办]  sci_tech\n",
       "2     [丘, 陵, 与, 平, 原]  sci_tech\n",
       "3  [颈, 病, 个, 怎, 么, 办]  sci_tech\n",
       "4     [山, 地, 与, 高, 原]  sci_tech\n",
       "5  [贫, 血, 个, 怎, 么, 办]  sci_tech\n",
       "6        [地, 球, 变, 动]  sci_tech\n",
       "7        [地, 心, 游, 记]  lib_arts\n",
       "8        [柳, 林, 风, 声]  lib_arts\n",
       "9     [极, 地, 与, 沙, 漠]  sci_tech"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another preview\n",
    "df_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('国', 12641), ('中', 10596), ('文', 8114), ('学', 7149), ('与', 6941), ('研', 5438), ('究', 5271), ('人', 4390), ('大', 4217), ('集', 4166), ('史', 4129), ('代', 4037), ('民', 3741), ('年', 3433), ('生', 3310), ('法', 3060), ('理', 2989), ('化', 2968), ('论', 2851), ('一', 2848), ('全', 2797), ('编', 2783), ('书', 2697), ('家', 2682), ('事', 2633), ('新', 2616), ('小', 2406), ('经', 2377), ('本', 2364), ('世', 2352), ('物', 2174), ('古', 2155), ('会', 2096), ('地', 2088), ('之', 1976), ('发', 1967), ('教', 1925), ('传', 1911), ('战', 1892), ('业', 1854), ('我', 1837), ('子', 1827), ('和', 1823), ('术', 1815), ('图', 1790), ('四', 1782), ('美', 1768), ('界', 1738), ('记', 1725), ('实', 1703)]\n",
      "2472\n"
     ]
    }
   ],
   "source": [
    "# Some exploration of the dataset\n",
    "\n",
    "freq_dict = collections.Counter(vocab_list)\n",
    "print(freq_dict.most_common(50))\n",
    "\n",
    "print(len(word2index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# More exploration\n",
    "# Find out the leaset common words, which are not dropped and has a frequecy above 10\n",
    "\n",
    "from operator import itemgetter\n",
    "import heapq\n",
    "import collections\n",
    "def least_common_values(array, to_find=None):\n",
    "    counter = collections.Counter(array)\n",
    "    if to_find is None:\n",
    "        return sorted(counter.items(), key=itemgetter(1), reverse=False)\n",
    "    return heapq.nsmallest(to_find, counter.items(), key=itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('劝', 10), ('叽', 10), ('〇', 10), ('钻', 10)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A preview\n",
    "least_common_values(freq_dict, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the index to words dictioanry\n",
    "index2word = {ii: word for word, ii in word2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "803"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A preview\n",
    "word2index[\"波\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate the vocabulary size\n",
    "vocab_size = len(word2index)\n",
    "\n",
    "# Maximum length of a feature vector\n",
    "max_len = 20\n",
    "\n",
    "# Create a 2d zero vector for later use\n",
    "features = np.zeros(shape=(sample_n, max_len), dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "(66431, 20)\n",
      "30.106426216675953\n",
      "(66431, 20)\n",
      "60.212852433351905\n",
      "(66431, 20)\n",
      "90.31927865002784\n",
      "(66431, 20)\n"
     ]
    }
   ],
   "source": [
    "# Convert words to feature vectors\n",
    "for ii, row in enumerate(df_list['features']):\n",
    "    for jj, word in enumerate(row):\n",
    "        if len(row) <= max_len:\n",
    "            len_row = max_len\n",
    "        else:\n",
    "            len_row = len(row)\n",
    "        \n",
    "        try:\n",
    "            features[ii][len_row - jj] = word2index[word]\n",
    "        except:\n",
    "            pass\n",
    "    if ii % 20000 == 0:  # For preview only\n",
    "        print(ii/sample_n*100)\n",
    "        print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0, 2211,  589, 2148, 1343, 1571])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another preview\n",
    "features[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One hot encode the label starts here\n",
    "\n",
    "# This cell removes some irregular and mistaken date\n",
    "df_label=df_list.copy()\n",
    "def NAN_remover(x):\n",
    "    if str(x) != 'nan':\n",
    "        return str(x)\n",
    "    else:\n",
    "        return 'lib_arts'\n",
    "\n",
    "df_label['CLASS_NO1'] = df_label['CLASS_NO1'].apply(NAN_remover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLASS_NO1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sci_tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sci_tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sci_tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sci_tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sci_tech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CLASS_NO1\n",
       "0  sci_tech\n",
       "1  sci_tech\n",
       "2  sci_tech\n",
       "3  sci_tech\n",
       "4  sci_tech"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another preview\n",
    "\n",
    "df_label=df_label.drop('features', axis=1)\n",
    "df_label[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lib_arts', 'sci_tech'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show all the labels \n",
    "\n",
    "np_label = np.array(df_label['CLASS_NO1'])\n",
    "\n",
    "set_label = set(np_label)\n",
    "set_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a number code for each class\n",
    "num2class = {'1': 'lib_arts',\n",
    "'2': 'sci_tech'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lib_arts': '1', 'sci_tech': '2'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inverse that dictionary\n",
    "class2num = {ii: word for word, ii in num2class.items()}\n",
    "class2num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def class2ohfunc(classno):\n",
    "    oh = [0,0]\n",
    "    oh[int(class2num[classno])-1] = 1\n",
    "    return np.array(oh)\n",
    "# One hot encoding for labels ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLASS_NO1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CLASS_NO1\n",
       "0    [0, 1]\n",
       "1    [0, 1]\n",
       "2    [0, 1]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A preview\n",
    "df_label['CLASS_NO1'] = df_label['CLASS_NO1'].apply(class2ohfunc)\n",
    "df_label[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2472\n"
     ]
    }
   ],
   "source": [
    "# Preview the shape of features\n",
    "features.shape\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Devide the dataset into training and testing sets \n",
    "# Shuffle is not applied, since the original dataset is unordered\n",
    "labels = np.array(df_label['CLASS_NO1'])\n",
    "labels = np.array(labels.tolist())\n",
    "trainX = features[:-6124]\n",
    "trainY = labels[:-6124]\n",
    "testX = features[-6124:]\n",
    "\n",
    "testY = labels[-6124:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0]\n",
      " [1 0]]\n"
     ]
    }
   ],
   "source": [
    "# A preview\n",
    "print(testY[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reshape the label\n",
    "trainY = np.reshape(trainY, newshape=(len(trainX),2))\n",
    "testY = np.reshape(testY, newshape=(len(testX),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60307, 20), (60307, 2))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another preview\n",
    "trainX.shape, trainY.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAINING SOON STARTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66431, 20)\n",
      "2472\n"
     ]
    }
   ],
   "source": [
    "# More previews to check the status\n",
    "print(features.shape)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build the model \n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(vocab_size, 400, input_length=max_len))\n",
    "\n",
    "model.add(LSTM(500))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#model.add(Dense(600, activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(120, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "adam_op = Adam(lr=0.004)\n",
    "#adam_op = Adam()\n",
    "#sgd_op = SGD(lr=0.06, decay=8e-6, momentum=1.0, nesterov=True)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam_op, metrics=[metrics.categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      "60307/60307 [==============================] - 8s - loss: 0.2934 - categorical_accuracy: 0.9007     \n",
      "Epoch 2/11\n",
      "60307/60307 [==============================] - 8s - loss: 0.1957 - categorical_accuracy: 0.9255     \n",
      "Epoch 3/11\n",
      "60307/60307 [==============================] - 8s - loss: 0.1690 - categorical_accuracy: 0.9348     \n",
      "Epoch 4/11\n",
      "60307/60307 [==============================] - 8s - loss: 0.1475 - categorical_accuracy: 0.9419     \n",
      "Epoch 5/11\n",
      "60307/60307 [==============================] - 8s - loss: 0.1307 - categorical_accuracy: 0.9480     \n",
      "Epoch 6/11\n",
      "60307/60307 [==============================] - 8s - loss: 0.1156 - categorical_accuracy: 0.9545     \n",
      "Epoch 7/11\n",
      "60307/60307 [==============================] - 8s - loss: 0.1003 - categorical_accuracy: 0.9603     \n",
      "Epoch 8/11\n",
      "60307/60307 [==============================] - 8s - loss: 0.0883 - categorical_accuracy: 0.9658     \n",
      "Epoch 9/11\n",
      "60307/60307 [==============================] - 8s - loss: 0.0759 - categorical_accuracy: 0.9701     \n",
      "Epoch 10/11\n",
      "60307/60307 [==============================] - 8s - loss: 0.0663 - categorical_accuracy: 0.9751     \n",
      "Epoch 11/11\n",
      "60307/60307 [==============================] - 8s - loss: 0.0578 - categorical_accuracy: 0.9776     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f256987828>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training starts\n",
    "model.fit(trainX, trainY, batch_size=512, epochs=11, verbose=1, callbacks=[cbk.TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_grads=True, write_images=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60224/60307 [============================>.] - ETA: 0s\n",
      "0.988409305719\n"
     ]
    }
   ],
   "source": [
    "# Training-set accuracy\n",
    "score = model.evaluate(trainX, trainY)\n",
    "print(\"\")\n",
    "print(score[1])\n",
    "\n",
    "# 5 epochs: 0.98365032251645745"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6048/6124 [============================>.] - ETA: 0s\n",
      "0.918517308948\n"
     ]
    }
   ],
   "source": [
    "# Testing-set accuracy\n",
    "score = model.evaluate(testX, testY)\n",
    "print(\"\")\n",
    "print(score[1])\n",
    "\n",
    "# 5 epochs: 0.9301110387315632\n",
    "# another: 0.933050293926"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"Final_Model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.00000000e+00   1.93321442e-10]\n"
     ]
    }
   ],
   "source": [
    "# Prediction starts here\n",
    "\n",
    "pred_list = np.zeros(shape=(len(testX),2))\n",
    "results = model.predict(testX)\n",
    "for i, res in enumerate(results):\n",
    "    result = res\n",
    "    if i == 1:\n",
    "        print(res) # Show the first prediction result\n",
    "    for jj in range(2):\n",
    "        pred_list[i][jj] = result[jj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.99984741e-01,   1.52766697e-05],\n",
       "       [  1.00000000e+00,   1.93321442e-10],\n",
       "       [  1.00000000e+00,   1.93321442e-10],\n",
       "       [  1.00000000e+00,   1.93321442e-10],\n",
       "       [  1.00000000e+00,   1.93321442e-10],\n",
       "       [  1.00000000e+00,   1.93321442e-10],\n",
       "       [  1.00000000e+00,   1.93321442e-10],\n",
       "       [  9.99956012e-01,   4.40421172e-05],\n",
       "       [  9.99988675e-01,   1.13214219e-05],\n",
       "       [  1.00000000e+00,   3.56028949e-08]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A preview\n",
    "pred_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lib_arts', 'lib_arts', 'lib_arts', 'lib_arts', 'lib_arts']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6124"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell maps the results to final classes\n",
    "\n",
    "def toClassNo(npArray):\n",
    "    i = 0\n",
    "    val = npArray[0]\n",
    "    for jj in range(len(npArray)-1):\n",
    "        if npArray[jj+1] > val:\n",
    "            val = npArray[jj+1]\n",
    "            i = jj + 1\n",
    "    return num2class[str(i+1)]\n",
    "\n",
    "pred_result_list = [None] * len(testX)\n",
    "for i, result in enumerate(pred_list):\n",
    "    pred_result_list[i] = toClassNo(result)\n",
    "\n",
    "print(pred_result_list[:5])\n",
    "len(pred_result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>CLASS_NO1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60307</th>\n",
       "      <td>柏杨全集</td>\n",
       "      <td>lib_arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60308</th>\n",
       "      <td>四部叢刊 :四編</td>\n",
       "      <td>lib_arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60309</th>\n",
       "      <td>四部叢刊 :四編</td>\n",
       "      <td>lib_arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60310</th>\n",
       "      <td>四部叢刊 :四編</td>\n",
       "      <td>lib_arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60311</th>\n",
       "      <td>四部叢刊 :四編</td>\n",
       "      <td>lib_arts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       features CLASS_NO1\n",
       "60307      柏杨全集  lib_arts\n",
       "60308  四部叢刊 :四編  lib_arts\n",
       "60309  四部叢刊 :四編  lib_arts\n",
       "60310  四部叢刊 :四編  lib_arts\n",
       "60311  四部叢刊 :四編  lib_arts"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One more preview\n",
    "df_raw[-6124:-6124+5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Output the testing data\n",
    "\n",
    "df_pred = pd.DataFrame(pred_result_list)\n",
    "df_pred.to_csv('output1.csv')\n",
    "output.to_csv('output2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
